{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of earnings\n",
    "Aim is to use details about a person to predict whether or no they earn more than $50,000 per year.\n",
    "\n",
    "Run the cell below to download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./data\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data -O ./data/adult.csv\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test -O ./data/adult_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Union, Optional, Tuple\n",
    "from collections import OrderedDict, defaultdict\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble.forest import ForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization, Input, Embedding, Reshape, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing\n",
    "The data is in *Comma Separated Value* (CSV) format. To load it up, we'll use Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/adult.csv', header=None); print(len(df)); df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/adult_test.csv', header=None, skiprows=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column names\n",
    "In the dataset as is, the features (columns) are just numbers. We can set them to a more human-readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [ \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\", \"MaritalStatus\", \"Occupation\",\n",
    "              \"Relationship\", \"Race\", \"Gender\", \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Target\"]\n",
    "df_test.columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a numerical target for our model, so we'll map <=50K to 0, and >50K to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df.Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = df.Target.map({' <=50K': 0, ' >50K': 1})\n",
    "df_test['Target'] = df.Target.map({' <=50K': 0, ' >50K': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a class imbalance, but we'll ignore it for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Target.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set\n",
    "Since we're fitting our model to data, we want to have an unbiased estimate of its performance to help optimise the architecture before we apply the model to the testing data. We can randomly sample a *validation* set from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_ids = train_test_split(df.index, stratify=df.Target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help reduce code overhead in the next step, we'll simply set flag in the data for whether or not we want to use each row for training or validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['val'] = 0\n",
    "df.loc[val_ids, 'val'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature processing\n",
    "The data contains both continuous features (real values with numerical comparison) and categorical features (discreet values or string labels with no numerical comparison). Each need to be treated slightly differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['WorkClass', 'Education', 'MaritalStatus', 'Occupation',\n",
    "             'Relationship', 'Race', 'Gender', 'NativeCountry']\n",
    "cont_feats = ['Age', 'fnlwgt', 'EducationNum', 'CapitalGain', 'CapitalLoss', 'HoursPerWeek']\n",
    "train_feats = cont_feats+cat_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical encoding\n",
    "Our model can only function on numbers, but the categorical features use strings. We can map these string values to integers in order to feed the data into our model. We also want to know whether there are categories which only appear in either training or testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in ['WorkClass', 'Education', 'MaritalStatus', 'Occupation',\n",
    "             'Relationship', 'Race', 'Gender', 'NativeCountry']:\n",
    "    print(feat, set(df[feat]) == set(df_test[feat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing from test:',  [f for f in set(df.NativeCountry) if f not in set(df_test.NativeCountry)])\n",
    "print('Missing from train:', [f for f in set(df_test.NativeCountry) if f not in set(df.NativeCountry)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the training data contains an extra country which doesn't appear in the testing data, however the model may well be able to learn things from the extra data which are invarient to country, so we'll keep it in.\n",
    "\n",
    "We need to ensure the same string --> integer mapping is applied to both training and testing, in order to make sure the data still has the same meaning when we apply the model to the testing data. We'll also construct dictionaries to keep track of the mapping. **N.B.** Pandas has a dedicated column type `Categorical` for helping with this kind of data, but we'll stick with integer mapping for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_maps = defaultdict(dict)\n",
    "for feat in ['WorkClass', 'Education', 'MaritalStatus', 'Occupation',\n",
    "             'Relationship', 'Race', 'Gender', 'NativeCountry']:\n",
    "    for i, val in enumerate(set(df[feat])):\n",
    "        cat_maps[feat][val] = i\n",
    "        df.loc[df[feat] == val, feat] = i\n",
    "        df_test.loc[df_test[feat] == val, feat] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, our data now only contains numerical information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous preprocessing\n",
    "The weight initialisation we use is optimal for inputs which are unit-Gaussian. The closest we can get is to shift and scale each feature to have mean zero and standard deviation one. `SK-Learn` has `Pipeline` classes to handle series of transformations to data, and we'll use the `StandardScaler` to transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pipe = Pipeline([('norm_in', StandardScaler(with_mean=True, with_std=True))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to fit the transformation to the data. Note the Boolean indexing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pipe.fit(df[df.val == 0][cont_feats].values.astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally apply the transformation to the training, validation, and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cont_feats] = input_pipe.transform(df[cont_feats].values.astype('float32'))\n",
    "df_test[cont_feats] = input_pipe.transform(df_test[cont_feats].values.astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the transformation by plotting an example feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Now we need to build a model to fit to the data. Use the previous two example notebooks to help write a function which returns an appropriate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_in:int, hidden_sizes:List[int], n_out:int=1, lr:float=1e-3) -> Model:\n",
    "    # Your code here______________________________________________________\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ____________________________________________________________________\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['acc'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(len(train_feats), [100, 100], 1, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to extract out our inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df[df.val == 0][train_feats], df[df.val == 0]['Target']\n",
    "x_val, y_val = df[df.val == 1][train_feats], df[df.val == 1]['Target']\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also useful to plot the training and validation performance evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hist:History) -> None:\n",
    "    with sns.axes_style('whitegrid'):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(24,8))\n",
    "        axs[0].plot(range(len(hist.history['loss'])), np.array(hist.history['loss']), label='Training')\n",
    "        axs[0].plot(range(len(hist.history['val_loss'])), np.array(hist.history['val_loss']), label='Validation')\n",
    "        axs[1].plot(range(len(hist.history['acc'])), np.array(hist.history['acc']), label='Training')\n",
    "        axs[1].plot(range(len(hist.history['val_acc'])), np.array(hist.history['val_acc']), label='Validation')\n",
    "\n",
    "        axs[0].set_ylabel(\"Loss\", fontsize=24)\n",
    "        axs[1].set_ylabel(\"Accuracy\", fontsize=24)\n",
    "        for ax in axs:\n",
    "            ax.legend(fontsize=16)\n",
    "            ax.set_xlabel(\"Epoch\", fontsize=24)\n",
    "            ax.tick_params(axis='x', labelsize=16)\n",
    "            ax.tick_params(axis='y', labelsize=16)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x=x, y=y, validation_data=(x_val, y_val), batch_size=128, epochs=30, verbose=0)\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-hot encoding\n",
    "Are treatment of categorical features so far has simply allowed use to feed the inputs into the model, however NNs have a continuous response to inputs and by encoding as integers we have implied a numerical comparison between categories.\n",
    "An encoding which removes this implication and allows the network to construct separate responses to each category is to expand each feature in to a series of features, one for each category, and mark the correct column with a 1, and the rest as zeros, e.g Monday --> (1,0,0,0,0,0,0)\n",
    "\n",
    "Pandas has a function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=cat_feats)\n",
    "df_test = pd.get_dummies(df_test, columns=cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the original categorical columns have been removed and replaced by dedicated columns for each feature category. We do need to remember about the missing category for `NativeCountry` which was not present in testing data, so we can add a column of zeros for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_maps['NativeCountry'][' Holand-Netherlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[f\"NativeCountry_{cat_maps['NativeCountry'][' Holand-Netherlands']}\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of input features has now shot up from 13 to 108: 1-hot encoding is not an efficient method, but should help our model to better access the information in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = [f for f in df.columns if f not in cont_feats+['Target', 'val']]\n",
    "train_feats = cont_feats+cat_feats\n",
    "len(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(len(train_feats), [100, 100], 1, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df[df.val == 0][train_feats], df[df.val == 0]['Target']\n",
    "x_val, y_val = df[df.val == 1][train_feats], df[df.val == 1]['Target']\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x=x, y=y, validation_data=(x_val, y_val), batch_size=128, epochs=30, verbose=0)\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularisation\n",
    "So, whilst the performance of the model improved, we can see overtime that the model begins to overtrain, resulting in a continual decrease in training loss, but this improvement does not transfer to the validation data; the model losses generalisation power.\n",
    "\n",
    "We can help combat this by applying *regularisation* techniques. One of the most popular is [Dropout](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf).\n",
    "\n",
    "Adapt your previous model construction function to apply Dropout at a set rate after each dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_do_model(n_in:int, hidden_sizes:List[int], n_out:int=1, lr:float=1e-3, do:float=0) -> Model:\n",
    "    # Your code here______________________________________________________\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ____________________________________________________________________\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['acc'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_do_model(len(train_feats), [100, 100], 1, lr=1e-3, do=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x=x, y=y, validation_data=(x_val, y_val), batch_size=128, epochs=30, verbose=0)\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully the model should now still reach about the same validation performance, but the overtraining should now be suppressed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
